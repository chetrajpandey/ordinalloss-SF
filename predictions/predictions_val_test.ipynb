{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e99d36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')  # Add the parent directory to the Python path\n",
    "from dsaa_code.models.cnns import Custom_ResNet34\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484ca11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.nn.functional import softmax\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", Warning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "023be985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:1' if use_cuda else 'cpu')\n",
    "print(torch.cuda.device_count())\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a58584",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyJP2Dataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, str(self.annotations.iloc[index, 0]), self.annotations.iloc[index, 2])\n",
    "        hmi = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(hmi)\n",
    "            \n",
    "        file = self.annotations.iloc[index, 2]\n",
    "        goes_class = self.annotations.iloc[index, 3]\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 4]))\n",
    "        LON_FWT = str(self.annotations.iloc[index, 6])\n",
    "        # lg_scale = torch.tensor(int(self.annotations.iloc[index, -1]))\n",
    "        \n",
    "        return (image, y_label, file, goes_class, LON_FWT)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac4a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/data/SHARPS/preprocessed_SHARPS_JPGS/stride_based_hourly_all/'\n",
    "val = '../labels/val_new.csv'\n",
    "test = '../labels/test_new.csv'\n",
    "#Define Transformations\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d279ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = MyJP2Dataset(csv_file = val, \n",
    "                            root_dir = datapath,\n",
    "                            transform = transformations)\n",
    "\n",
    "test_set = MyJP2Dataset(csv_file = test, \n",
    "                            root_dir = datapath,\n",
    "                            transform = transformations)\n",
    "\n",
    "\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=512, num_workers=8, pin_memory = True, shuffle = False)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=512, num_workers=8, pin_memory = True, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb05bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_PATH1_bce = '../trained_models/bce.pth'\n",
    "model_PATH2_bcesf = '../trained_models/bce_sf.pth'\n",
    "bce_wt = torch.load(model_PATH1_bce)\n",
    "bcesf_wt = torch.load(model_PATH2_bcesf)\n",
    "resnet = Custom_ResNet34(ipt_size=(512, 512)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0028259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_Compatible_preds_and_targets(model_prediction_list, model_target_list, model_path_list, model_goes_list, model_LON_FWT_list):\n",
    "    y_pred_list = []\n",
    "    preds = []\n",
    "    target_list = []\n",
    "    tgts = []\n",
    "    path_list = []\n",
    "    path = []\n",
    "    goes_list = []\n",
    "    goes = []\n",
    "    LON_FWT_list = []\n",
    "    LON_FWT = []\n",
    "    y_pred_list = [a.squeeze().tolist() for a in model_prediction_list]\n",
    "    preds = [item for sublist in y_pred_list for item in sublist]\n",
    "    target_list = [a.squeeze().tolist() for a in model_target_list]\n",
    "    tgts = [item for sublist in target_list for item in sublist]\n",
    "    path_list = [a for a in model_path_list]\n",
    "    path = [item for sublist in path_list for item in sublist]\n",
    "    \n",
    "    goes_list = [a for a in model_goes_list]\n",
    "    goes = [item for sublist in goes_list for item in sublist]\n",
    "    LON_FWT_list = [a for a in model_LON_FWT_list]\n",
    "    LON_FWT = [item for sublist in LON_FWT_list for item in sublist]\n",
    "    return preds,tgts, path, goes, LON_FWT\n",
    "\n",
    "\n",
    "def accuracy_score(prediction, target):\n",
    "    TN, FP, FN, TP = confusion_matrix(target, prediction).ravel()\n",
    "    print(\"TP: \", TP, \"FP: \", FP, \"TN: \", TN, \"FN: \", FN)\n",
    "    #TSS Computation also known as \"recall\"\n",
    "    tp_rate = TP / float(TP + FN) if TP > 0 else 0  \n",
    "    fp_rate = FP / float(FP + TN) if FP > 0 else 0\n",
    "    TSS = tp_rate - fp_rate\n",
    "    \n",
    "    #HSS2 Computation\n",
    "    N = TN + FP\n",
    "    P = TP + FN\n",
    "    HSS = (2 * (TP * TN - FN * FP)) / float((P * (FN + TN) + (TP + FP) * N))\n",
    "    \n",
    "    geomean = math.sqrt(abs(TSS)*abs(HSS))\n",
    "\n",
    "    return TSS, HSS, geomean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f305b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(checkpoint, test_model, test_loader, desc ):\n",
    "    test_target_list=[]\n",
    "    test_prediction_list=[]\n",
    "    test_path_list = []\n",
    "    test_goes_list = []\n",
    "    test_lonfwt_list = []\n",
    "    test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    test_model.eval()\n",
    "    print('***********************', desc, '*************************')\n",
    "    with torch.no_grad():\n",
    "        for d, t, path, goes, lonfwt in test_loader:\n",
    "            # Get data to cuda if possible\n",
    "            d = d.to(device=device)\n",
    "            t = t.to(device=device)\n",
    "\n",
    "            test_target_list.append(t)\n",
    "            test_path_list.append(list(path))\n",
    "            test_goes_list.append(list(goes))\n",
    "            test_lonfwt_list.append(list(lonfwt))\n",
    "\n",
    "            s = test_model(d)\n",
    "\n",
    "            p = softmax(s,dim=1)\n",
    "#             print(p.shape)\n",
    "\n",
    "            test_prediction_list.append(p[:,1])\n",
    "\n",
    "            del d,t,s,p\n",
    "            \n",
    "    a, b, pth, gc, lon = sklearn_Compatible_preds_and_targets(test_prediction_list, test_target_list,\n",
    "                                                   test_path_list,test_goes_list, test_lonfwt_list)\n",
    "    preds = [int(i >=0.5) for i in a]\n",
    "    print(accuracy_score(preds, b))\n",
    "    prob_list = pd.DataFrame(\n",
    "    {\n",
    "     'flare_prob': a,\n",
    "     'target': b,\n",
    "     'path': pth,\n",
    "     'goes_class': gc,\n",
    "     'lon_fwt': lon\n",
    "    })\n",
    "\n",
    "    print(prob_list['target'].value_counts())\n",
    "#     prob_list['timestamp'] = prob_list['timestamp'].apply(lambda row: row[35:-4])\n",
    "#     prob_list['timestamp'] = pd.to_datetime(prob_list['timestamp'], format='%Y.%m.%d_%H.%M.%S')\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd323448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** BCE *************************\n",
      "*********************** Validation *************************\n",
      "TP:  1765 FP:  8690 TN:  116382 FN:  613\n",
      "(0.6727403737062254, 0.2523420068357761, 0.4120202130727071)\n",
      "target\n",
      "0    125072\n",
      "1      2378\n",
      "Name: count, dtype: int64\n",
      "*********************** Test *************************\n",
      "TP:  2108 FP:  8862 TN:  121003 FN:  990\n",
      "(0.6121988974148727, 0.2732800580765497, 0.4090253662548768)\n",
      "target\n",
      "0    129865\n",
      "1      3098\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "*********************** BCESF *************************\n",
      "*********************** Validation *************************\n",
      "TP:  1749 FP:  8236 TN:  116836 FN:  629\n",
      "(0.6696419397330418, 0.2606581446142492, 0.41778897252883723)\n",
      "target\n",
      "0    125072\n",
      "1      2378\n",
      "Name: count, dtype: int64\n",
      "*********************** Test *************************\n",
      "TP:  1972 FP:  8187 TN:  121678 FN:  1126\n",
      "(0.5734973128598037, 0.2714882639592043, 0.3945855925570227)\n",
      "target\n",
      "0    129865\n",
      "1      3098\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('*********************** BCE *************************')\n",
    "bce_val = predict(bce_wt, resnet, val_loader, 'Validation')\n",
    "bce_test = predict(bce_wt, resnet, test_loader, 'Test')\n",
    "\n",
    "print('\\n\\n')\n",
    "print('*********************** BCESF *************************')\n",
    "bcesf_val = predict(bcesf_wt, resnet, val_loader, 'Validation')\n",
    "bcesf_test = predict(bcesf_wt, resnet, test_loader, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31cb8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(data, name, model_name):\n",
    "    data.to_csv(f'{model_name}.csv', index=False, header=True,\n",
    "                columns=['flare_prob', 'target', 'path', 'goes_class', 'lon_fwt'])\n",
    "save_results(bce_val, 'val', 'bce_val')\n",
    "save_results(bce_test, 'test', 'bce_test')\n",
    "# save_results(bcesf_val, 'val', 'bcesf_val')\n",
    "# save_results(bcesf_test, 'test', 'bcesf_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a1c22",
   "metadata": {},
   "source": [
    "### LATER ADDED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb389be3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 44.40 GiB of which 3.31 MiB is free. Process 169810 has 42.68 GiB memory in use. Process 1741869 has 1.70 GiB memory in use. Of the allocated memory 319.65 MiB is allocated by PyTorch, and 26.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_PATH3_bcesf \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../trained_models/best_loss_ord_ce.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m bcesf_wt_new \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_PATH3_bcesf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1427\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1392\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1391\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1392\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1366\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1365\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1366\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1367\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1368\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1371\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:381\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 381\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:279\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(obj\u001b[38;5;241m.\u001b[39mnbytes(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(location))\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:114\u001b[0m, in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_type(indices, values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     untyped_storage\u001b[38;5;241m.\u001b[39mcopy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 44.40 GiB of which 3.31 MiB is free. Process 169810 has 42.68 GiB memory in use. Process 1741869 has 1.70 GiB memory in use. Of the allocated memory 319.65 MiB is allocated by PyTorch, and 26.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model_PATH3_bcesf = '../trained_models/best_loss_ord_ce.pth'\n",
    "bcesf_wt_new = torch.load(model_PATH3_bcesf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e68803f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** BCESF *************************\n",
      "*********************** Validation *************************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*********************** BCESF *************************\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m bcesf_val_new \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbcesf_wt_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mValidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m bcesf_test_new \u001b[38;5;241m=\u001b[39m predict(bcesf_wt_new, resnet, test_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(checkpoint, test_model, test_loader, desc)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d, t, path, goes, lonfwt \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# Get data to cuda if possible\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         d \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m         t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     16\u001b[0m         test_target_list\u001b[38;5;241m.\u001b[39mappend(t)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('*********************** BCESF *************************')\n",
    "bcesf_val_new = predict(bcesf_wt_new, resnet, val_loader, 'Validation')\n",
    "bcesf_test_new = predict(bcesf_wt_new, resnet, test_loader, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027326a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(bcesf_val_new, 'val', 'bcesf_val_new')\n",
    "save_results(bcesf_test_new, 'test', 'bcesf_test_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d76272c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = ['#1E90FF', '#FF6347', '#FF8C00','#3CB371']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, color in enumerate(colors):\n",
    "    ax.plot([0, 1], [i, i], color=color, linewidth=10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd7ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
